import argparse
import os
import re
import json
import random
from typing import Dict, Tuple, List
from concurrent.futures import ThreadPoolExecutor, as_completed

from PIL import Image

# è·¯å¾‘è¨­å®š
BASE_SLIDE_DIR = "base_slide"
MAGIC_IMG_DIR = "./magicbrush_converted/images"
MAGIC_META_DIR = "./magicbrush_converted/meta"

DATASET_ROOT = "./dataset"  # è¼¸å‡ºå½±åƒï¼šdataset/<train|validation|test>
GT_ROOT = "./gt"            # è¼¸å‡ºæ¨™è¨»ï¼šgt/<train|validation|test>/meta.json

BBOX_JSON = "bboxes.json"

# MagicBrush train splitï¼šå‰ 4000 å¼µç•¶ trainï¼Œå‰©ä¸‹å°¾ç«¯ 512 å¼µç•¶ validation
TRAIN_MAX_IDS = 4000
VAL_TAIL_IDS = 512


def load_json(path: str, default):
    if not os.path.exists(path):
        return default
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def save_json(path: str, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_magicbrush_turn1(image_dir: str) -> Dict[str, Dict[str, Dict[str, str]]]:
    """
    æƒæ ./magicbrush_converted/images åº•ä¸‹æ‰€æœ‰
    train_<id>_turn1_source.png
    dev_<id>_turn1_source.png

    å›å‚³ï¼š
    {
      "train": {
        "<id>": {"source":..., "target":..., "mask":...},
        ...
      },
      "dev": {
        "<id>": {...},
        ...
      }
    }
    """
    grouped: Dict[str, Dict[str, Dict[str, str]]] = {
        "train": {},
        "dev": {},
    }

    pattern = re.compile(r"^(train|dev)_(\d+)_turn1_source\.png$")

    for fname in os.listdir(image_dir):
        m = pattern.match(fname)
        if not m:
            continue

        split, magic_id = m.group(1), m.group(2)
        base = f"{split}_{magic_id}_turn1"

        src_path = os.path.join(image_dir, f"{base}_source.png")
        tgt_path = os.path.join(image_dir, f"{base}_target.png")
        msk_path = os.path.join(image_dir, f"{base}_mask.png")

        if not (os.path.exists(src_path) and os.path.exists(tgt_path) and os.path.exists(msk_path)):
            continue

        grouped[split][magic_id] = {
            "source": src_path,
            "target": tgt_path,
            "mask": msk_path,
        }

    if not grouped["train"] and not grouped["dev"]:
        raise RuntimeError(
            f"åœ¨ {image_dir} æ‰¾ä¸åˆ°ä»»ä½• train/dev_<id>_turn1_source/target/mask.png triplet"
        )

    return grouped


def load_bboxes_for_page(page_id: str) -> List[Tuple[int, int, int, int]]:
    db = load_json(BBOX_JSON, {})
    if page_id not in db:
        raise KeyError(f"{BBOX_JSON} ä¸­æ²’æœ‰ key '{page_id}' çš„ bbox è¨­ç½®")

    bdict = db[page_id]
    boxes = []
    for k in sorted(bdict.keys()):
        x1, y1, x2, y2 = bdict[k]
        boxes.append((int(x1), int(y1), int(x2), int(y2)))
    if not boxes:
        raise RuntimeError(f"{BBOX_JSON} ä¸­ '{page_id}' é›–ç„¶æœ‰ keyï¼Œä½†æ²’æœ‰ä»»ä½• bbox è¨­ç½®")
    return boxes


def compute_placement(
    bbox: Tuple[int, int, int, int],
    patch_size: Tuple[int, int],
) -> Tuple[int, int, int, int]:
    bx1, by1, bx2, by2 = bbox
    bw = bx2 - bx1
    bh = by2 - by1

    pw, ph = patch_size
    if pw <= 0 or ph <= 0:
        raise ValueError("patch å°ºå¯¸ä¸åˆæ³•")

    base_scale = min(bw / pw, bh / ph, 1.0)
    new_w0 = max(1, int(pw * base_scale))
    new_h0 = max(1, int(ph * base_scale))

    new_w, new_h = new_w0, new_h0

    MIN_SIDE = 200
    if new_w0 >= MIN_SIDE and new_h0 >= MIN_SIDE:
        min_scale = max(MIN_SIDE / new_w0, MIN_SIDE / new_h0)
        min_scale = min(max(min_scale, 0.0), 1.0)
        s = random.uniform(min_scale, 1.0)
        new_w = max(1, int(new_w0 * s))
        new_h = max(1, int(new_h0 * s))
        new_w = max(new_w, MIN_SIDE)
        new_h = max(new_h, MIN_SIDE)
        new_w = min(new_w, bw)
        new_h = min(new_h, bh)

    max_x = bx2 - new_w
    max_y = by2 - new_h
    if max_x < bx1 or max_y < by1:
        left = bx1
        top = by1
    else:
        left = random.randint(bx1, max_x)
        top = random.randint(by1, max_y)

    return left, top, new_w, new_h


def paste_patch(
    base_img: Image.Image,
    patch_img: Image.Image,
    left: int,
    top: int,
    new_w: int,
    new_h: int,
) -> Image.Image:
    patch_resized = patch_img.resize((new_w, new_h), resample=Image.LANCZOS)
    out = base_img.copy()
    if patch_resized.mode == "RGBA":
        out.paste(patch_resized, (left, top), mask=patch_resized)
    elif patch_resized.mode == "L" and base_img.mode == "L":
        out.paste(patch_resized, (left, top))
    else:
        out.paste(patch_resized, (left, top))
    return out


def parse_page_list(raw: str) -> List[str]:
    """
    "001, 002,003" -> ["001","002","003"]
    """
    if not raw:
        return []
    return [item.strip() for item in raw.split(",") if item.strip()]


def load_instruction(magic_split: str, magic_id: str) -> str:
    """
    å¾ ./magicbrush_converted/meta/<magic_split>_<id>_turn1.json è®€å– instruction ç•¶ä½œ promptã€‚
    magic_split: "train" æˆ– "dev"
    """
    meta_filename = f"{magic_split}_{magic_id}_turn1.json"
    meta_path = os.path.join(MAGIC_META_DIR, meta_filename)
    if not os.path.exists(meta_path):
        print(f"âš  æ‰¾ä¸åˆ° meta æª”æ¡ˆï¼š{meta_path}ï¼Œæ­¤ id çš„ prompt æœƒè¨­ç‚º None")
        return None

    data = load_json(meta_path, {})
    prompt = data.get("instruction", None)
    if prompt is None:
        print(f"âš  {meta_path} ä¸­æ²’æœ‰ 'instruction' æ¬„ä½ï¼Œprompt æœƒè¨­ç‚º None")
    return prompt


def build_existing_name_set(meta_obj):
    """
    å¾æ—¢æœ‰ meta ä¸­è’é›†æ‰€æœ‰å‡ºç¾éçš„æª”åï¼ˆsource/target/maskï¼‰ï¼Œé¿å…é‡è¤‡ã€‚
    """
    names = set()
    for s in meta_obj.get("samples", []):
        for k in ("source", "target", "mask"):
            if k in s:
                names.add(s[k])
    return names


def worker_task(
    split_name: str,
    page_id: str,
    magic_id: str,
    idx_str: str,
    magic_split: str,
    id_info: Dict[str, str],
    out_dir: str,
) -> dict | None:
    """
    å–®ä¸€ sample çš„å·¥ä½œï¼š
    - è®€å– base slide / MagicBrush patches
    - éš¨æ©Ÿé¸ bbox èˆ‡æ”¾ç½®ä½ç½®
    - ç”¢ç”Ÿ source/target/mask åœ–ç‰‡
    - å›å‚³ meta entryï¼ˆæˆ– None è¡¨ç¤ºè·³éï¼‰
    """
    base_path = os.path.join(BASE_SLIDE_DIR, f"{page_id}.png")
    if not os.path.exists(base_path):
        print(f"âš  [thread:{split_name}] æ‰¾ä¸åˆ° base slide åœ–ç‰‡ï¼š{base_path}ï¼Œè·³éã€‚")
        return None

    try:
        bboxes = load_bboxes_for_page(page_id)
    except Exception as e:
        print(f"âš  [thread:{split_name}] è¼‰å…¥ {page_id} çš„ bbox å¤±æ•—ï¼š{e}ï¼Œè·³éã€‚")
        return None

    if not bboxes:
        print(f"âš  [thread:{split_name}] {page_id} æ²’æœ‰ä»»ä½• bboxï¼Œè·³éã€‚")
        return None

    base_img = Image.open(base_path).convert("RGB")
    W, H = base_img.size

    src_path = id_info["source"]
    tgt_path = id_info["target"]
    msk_path = id_info["mask"]
    prompt = id_info["prompt"]

    if not (os.path.exists(src_path) and os.path.exists(tgt_path) and os.path.exists(msk_path)):
        print(f"âš  [thread:{split_name}] MagicBrush åœ–ç‰‡ç¼ºå¤± id={magic_id}ï¼Œè·³éã€‚")
        return None

    src_patch = Image.open(src_path).convert("RGBA")
    tgt_patch = Image.open(tgt_path).convert("RGBA")
    msk_patch = Image.open(msk_path).convert("L")

    bbox = random.choice(bboxes)
    left, top, new_w, new_h = compute_placement(bbox, src_patch.size)
    x1, y1, x2, y2 = left, top, left + new_w, top + new_h

    src_name = f"{page_id}_{magic_id}_source_{idx_str}.png"
    tgt_name = f"{page_id}_{magic_id}_target_{idx_str}.png"
    mask_name = f"{page_id}_{magic_id}_mask_{idx_str}.png"

    out_source_path = os.path.join(out_dir, src_name)
    out_target_path = os.path.join(out_dir, tgt_name)
    out_mask_path = os.path.join(out_dir, mask_name)

    # å¯¦éš›è¼¸å‡ºåœ–ç‰‡
    slide_source = paste_patch(base_img, src_patch, left, top, new_w, new_h)
    slide_source.save(out_source_path)

    slide_target = paste_patch(base_img, tgt_patch, left, top, new_w, new_h)
    slide_target.save(out_target_path)

    base_mask = Image.new("L", (W, H), 0)
    mask_img_res = paste_patch(base_mask, msk_patch, left, top, new_w, new_h)
    mask_img_res.save(out_mask_path)

    print(
        f"[{split_name}] page={page_id}, magic_id={magic_id}, sample={idx_str}, "
        f"bbox=({x1},{y1},{x2},{y2})"
    )

    return {
        "source": src_name,
        "target": tgt_name,
        "mask": mask_name,
        "bbox": [x1, y1, x2, y2],
        "prompt": prompt,
    }


def main():
    parser = argparse.ArgumentParser(
        description=(
            "æ ¹æ“š bboxes.json èˆ‡ MagicBrush (turn1)ï¼Œ"
            "ç”¢ç”Ÿ dataset/<train|validation|test> èˆ‡ gt/<train|validation|test>/meta.jsonã€‚"
        )
    )
    parser.add_argument(
        "-n",
        "--num",
        type=int,
        default=1,
        help="æ¯å€‹ MagicBrush åœ–ç‰‡åœ¨æ¯å¼µèƒŒæ™¯æŠ•å½±ç‰‡ä¸Šè¦éš¨æ©Ÿç”Ÿæˆå¹¾å¼µåˆæˆåœ–ï¼ˆé è¨­ 1ï¼‰",
    )
    parser.add_argument(
        "-t",
        "--test-run",
        action="store_true",
        help="æ¸¬è©¦æ¨¡å¼ï¼šæ¯å€‹åˆ†å€åªç”¢ç”Ÿä¸€å¼µç…§ç‰‡ï¼ˆ1 å€‹ page Ã— 1 å€‹ MagicBrush id Ã— 1 å¼µ sampleï¼‰",
    )
    parser.add_argument(
        "-w",
        "--workers",
        type=int,
        default=4,
        help="å¹³è¡ŒåŸ·è¡Œçš„ thread æ•¸é‡ï¼ˆé è¨­ 4ï¼Œè¨­ç‚º 1 å‰‡æ”¹ç‚ºå–®ç·šç¨‹åŸ·è¡Œï¼‰",
    )
    args = parser.parse_args()

    # èƒŒæ™¯æŠ•å½±ç‰‡åˆ†é…åˆ°ä¸åŒ split
    train_pages = [
        "001", "002", "003", "004", "005", "006", "008", "010",
        "013", "014", "017", "023", "025", "027", "029", "030",
        "031", "032", "034", "037", "039", "042", "043", "045",
        "048", "050", "056", "060", "061", "063", "064", "068", "072"
    ]
    val_pages = [
        "009", "012", "016", "019", "024", "028", "036",
        "040", "053", "054", "059", "065", "069", "073"
    ]
    test_pages = [
        "007", "011", "015", "018", "020", "021", "022", "026",
        "033", "035", "038", "041", "044", "046", "047", "049",
        "051", "052", "055", "057", "058", "062", "066", "067",
        "070", "071", "074", "075"
    ]
    num_per_id = args.num

    if not train_pages and not val_pages and not test_pages:
        raise ValueError("train-pages / val-pages / test-pages è‡³å°‘è¦æŒ‡å®šä¸€å€‹éç©ºã€‚")

    # 1. è¼‰å…¥ MagicBrush åœ–ç‰‡ï¼ˆturn1ï¼‰
    grouped_all = load_magicbrush_turn1(MAGIC_IMG_DIR)

    # 2. ä¾ç…§è¦å‰‡æ‹†æˆä¸‰çµ„ï¼š
    #    - trainï¼štrain split çš„å‰ 4000 å€‹ id
    #    - validationï¼štrain split å‰©ä¸‹çš„å°¾ç«¯ 512 å€‹ id
    #    - testï¼šdev split çš„æ‰€æœ‰ id
    train_ids_sorted = sorted(grouped_all["train"].keys(), key=lambda x: int(x))
    dev_ids_sorted = sorted(grouped_all["dev"].keys(), key=lambda x: int(x))

    train_ids_for_train = train_ids_sorted[:TRAIN_MAX_IDS]
    remaining_train_ids = train_ids_sorted[TRAIN_MAX_IDS:]
    if len(remaining_train_ids) >= VAL_TAIL_IDS:
        train_ids_for_val = remaining_train_ids[-VAL_TAIL_IDS:]
    else:
        train_ids_for_val = remaining_train_ids

    print(f"ğŸ§© MagicBrush train ç¸½å…± {len(train_ids_sorted)} å€‹ id")
    print(f"  - train ä½¿ç”¨å‰ {len(train_ids_for_train)} å€‹ id")
    print(f"  - validation ä½¿ç”¨å¾Œ {len(train_ids_for_val)} å€‹ idï¼ˆå¾å‰©é¤˜çš„ train ä¸­å–å°¾ç«¯ï¼‰")
    print(f"ğŸ§© MagicBrush dev ç¸½å…± {len(dev_ids_sorted)} å€‹ idï¼ˆå…¨éƒ¨çµ¦ test ä½¿ç”¨ï¼‰")

    ids_train_dict = {mid: grouped_all["train"][mid] for mid in train_ids_for_train}
    ids_val_dict = {mid: grouped_all["train"][mid] for mid in train_ids_for_val}
    ids_test_dict = {mid: grouped_all["dev"][mid] for mid in dev_ids_sorted}

    # 3. æº–å‚™ä¸‰å€‹ split çš„è¨­å®š
    splits = {
        "train": {
            "pages": train_pages,
            "magic_split": "train",
            "ids_dict": ids_train_dict,
        },
        "validation": {
            "pages": val_pages,
            "magic_split": "train",
            "ids_dict": ids_val_dict,
        },
        "test": {
            "pages": test_pages,
            "magic_split": "dev",
            "ids_dict": ids_test_dict,
        },
    }

    # å¦‚æœæ˜¯æ¸¬è©¦æ¨¡å¼ï¼šæ¯å€‹ split åªæ‹¿ 1 å€‹ page + 1 å€‹ magic_idï¼Œä¸”æ¯å€‹ id åªç”¢ç”Ÿ 1 å¼µ
    if args.test_run:
        print("âš™ å•Ÿç”¨æ¸¬è©¦æ¨¡å¼ï¼šæ¯å€‹ split åªç”¢ç”Ÿä¸€å¼µç…§ç‰‡")
        for split_name, cfg in splits.items():
            pages = cfg["pages"]
            ids_dict = cfg["ids_dict"]

            if pages:
                cfg["pages"] = pages[:1]
            if ids_dict:
                first_id = sorted(ids_dict.keys(), key=lambda x: int(x))[0]
                cfg["ids_dict"] = {first_id: ids_dict[first_id]}

        num_per_id = 1  # æ¸¬è©¦æ¨¡å¼å›ºå®šæ¯å€‹ id åªç”Ÿä¸€å¼µ

    # 4. é‡å° train / validation / test å„åˆ¥ç”¢å‡ºï¼š
    #    - dataset/<split>/*.png
    #    - gt/<split>/meta.json
    for split_name, cfg in splits.items():
        pages = cfg["pages"]
        ids_dict = cfg["ids_dict"]
        magic_split = cfg["magic_split"]

        if not pages:
            print(f"âš  split={split_name} æ²’æœ‰æŒ‡å®šä»»ä½•èƒŒæ™¯æŠ•å½±ç‰‡ï¼Œè·³éã€‚")
            continue
        if not ids_dict:
            print(f"âš  split={split_name} æ²’æœ‰ä»»ä½• MagicBrush åœ–ç‰‡å¯ç”¨ï¼Œè·³éã€‚")
            continue

        out_dir = os.path.join(DATASET_ROOT, split_name)
        gt_dir = os.path.join(GT_ROOT, split_name)
        os.makedirs(out_dir, exist_ok=True)
        os.makedirs(gt_dir, exist_ok=True)

        meta_path = os.path.join(gt_dir, "meta.json")
        meta_obj = load_json(meta_path, {"samples": []})
        existing_names = build_existing_name_set(meta_obj)

        print(f"\n========== è™•ç† split={split_name} ==========")
        print(f"ğŸ“„ èƒŒæ™¯æŠ•å½±ç‰‡é æ•¸ï¼š{len(pages)}")
        print(f"ğŸ–¼ MagicBrush id æ•¸é‡ï¼š{len(ids_dict)}")
        print(f"ğŸ“ è¼¸å‡ºå½±åƒè³‡æ–™å¤¾ï¼š{out_dir}")
        print(f"ğŸ“ è¼¸å‡º GT æª”æ¡ˆï¼š{meta_path}")

        # é å…ˆè¼‰å…¥æ¯å€‹ MagicBrush id çš„ prompt
        id_infos: Dict[str, Dict[str, str]] = {}
        for magic_id, paths in ids_dict.items():
            prompt = load_instruction(magic_split, magic_id)
            id_infos[magic_id] = {
                "source": paths["source"],
                "target": paths["target"],
                "mask": paths["mask"],
                "prompt": prompt,
            }

        # å»ºç«‹æ‰€æœ‰è¦è™•ç†çš„ä»»å‹™åˆ—è¡¨
        tasks: List[Tuple[str, str, str, str, Dict[str, str], str]] = []
        for page_id in pages:
            for magic_id in sorted(id_infos.keys(), key=lambda x: int(x)):
                for idx in range(1, num_per_id + 1):
                    idx_str = f"{idx:03d}"
                    src_name = f"{page_id}_{magic_id}_source_{idx_str}.png"
                    tgt_name = f"{page_id}_{magic_id}_target_{idx_str}.png"
                    mask_name = f"{page_id}_{magic_id}_mask_{idx_str}.png"

                    out_source_path = os.path.join(out_dir, src_name)
                    out_target_path = os.path.join(out_dir, tgt_name)
                    out_mask_path = os.path.join(out_dir, mask_name)

                    # è‹¥æª”åå·²å‡ºç¾åœ¨ meta æˆ–å¯¦é«”æª”æ¡ˆå·²å­˜åœ¨ï¼Œå°±ç›´æ¥è·³éé€™å€‹ä»»å‹™
                    if (
                        src_name in existing_names
                        or tgt_name in existing_names
                        or mask_name in existing_names
                        or os.path.exists(out_source_path)
                        or os.path.exists(out_target_path)
                        or os.path.exists(out_mask_path)
                    ):
                        print(
                            f"âš  [{split_name}] æª”åå·²å­˜åœ¨ï¼Œç•¥éæ—¢æœ‰ sample: "
                            f"{src_name}, {tgt_name}, {mask_name}"
                        )
                        continue

                    tasks.append(
                        (
                            split_name,
                            page_id,
                            magic_id,
                            idx_str,
                            magic_split,
                            id_infos[magic_id],
                            out_dir,
                        )
                    )

        print(f"ğŸ§µ split={split_name} ç¸½ä»»å‹™æ•¸é‡ï¼š{len(tasks)}ï¼ˆthreads={args.workers}ï¼‰")

        # åŸ·è¡Œä»»å‹™ï¼ˆå¹³è¡Œæˆ–å–®ç·šç¨‹ï¼‰
        new_samples: List[dict] = []

        if args.workers == 1:
            # å–®ç·šç¨‹åŸ·è¡Œï¼Œæ–¹ä¾¿ debug
            for t in tasks:
                result = worker_task(*t)
                if result is not None:
                    new_samples.append(result)
                    existing_names.add(result["source"])
                    existing_names.add(result["target"])
                    existing_names.add(result["mask"])
        else:
            with ThreadPoolExecutor(max_workers=args.workers) as executor:
                future_to_task = {
                    executor.submit(worker_task, *t): t for t in tasks
                }
                for future in as_completed(future_to_task):
                    result = future.result()
                    if result is not None:
                        new_samples.append(result)
                        existing_names.add(result["source"])
                        existing_names.add(result["target"])
                        existing_names.add(result["mask"])

        # æŠŠæ–°ç”¢ç”Ÿçš„ samples åŠ é€² meta
        meta_obj["samples"].extend(new_samples)
        save_json(meta_path, meta_obj)
        print(f"ğŸ’¾ split={split_name} å®Œæˆï¼Œæ–°å¢ {len(new_samples)} ç­†æ¨£æœ¬ï¼Œå·²æ›´æ–° {meta_path}")

    print("\nâœ… å®Œæˆæ‰€æœ‰ split çš„åˆæˆèˆ‡æ¨™è¨»è¼¸å‡º")
    print(f"  - å½±åƒï¼š{DATASET_ROOT}/<train|validation|test>")
    print(f"  - GT  ï¼š{GT_ROOT}/<train|validation|test>/meta.json")


if __name__ == "__main__":
    main()
